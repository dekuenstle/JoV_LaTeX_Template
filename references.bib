

@article{ekmanDimensionsColorVision1954,
  title = {Dimensions of {{Color Vision}}},
  author = {Ekman, Gosta},
  year = {1954},
  journal = {The Journal of Psychology},
  volume = {38},
  number = {2},
  pages = {467--474},
  doi = {10.1080/00223980.1954.9712953}
}

@article{gescheiderPsychophysicalScaling1988,
  title = {Psychophysical {{Scaling}}},
  author = {Gescheider, G. A.},
  year = {1988},
  journal = {Annual Review of Psychology},
  volume = {39},
  number = {1},
  pages = {169--200}
}

@article{gowerGeneralizedProcrustesAnalysis1975,
  title = {Generalized Procrustes Analysis},
  author = {Gower, J. C.},
  year = {1975},
  month = mar,
  journal = {Psychometrika},
  volume = {40},
  number = {1},
  pages = {33--51},
  issn = {1860-0980},
  doi = {10.1007/BF02291478},
  abstract = {SupposePi(i)(i = 1, 2, ...,m, j = 1, 2, ...,n) give the locations ofmn points inp-dimensional space. Collectively these may be regarded asm configurations, or scalings, each ofn points inp-dimensions. The problem is investigated of translating, rotating, reflecting and scaling them configurations to minimize the goodness-of-fit criterion {$\Sigma$}i=1m{$\Sigma$}i=1n{$\Delta$}2(Pj(i)Gi), whereGiis the centroid of them pointsPi(i)(i = 1, 2, ...,m). The rotated positions of each configuration may be regarded as individual analyses with the centroid configuration representing a consensus, and this relationship with individual scaling analysis is discussed. A computational technique is given, the results of which can be summarized in analysis of variance form. The special casem = 2 corresponds to Classical Procrustes analysis but the choice of criterion that fits each configuration to the common centroid configuration avoids difficulties that arise when one set is fitted to the other, regarded as fixed.},
  langid = {english},
  file = {/home/dek/Zotero/storage/V3M8HP7T/Gower - 1975 - Generalized procrustes analysis.pdf}
}

@article{haghiriComparisonBasedFrameworkPsychophysics2019,
  title = {Comparison-{{Based Framework}} for {{Psychophysics}}: {{Lab}} versus {{Crowdsourcing}}},
  shorttitle = {Comparison-{{Based Framework}} for {{Psychophysics}}},
  author = {Haghiri, Siavash and Rubisch, Patricia and Geirhos, Robert and Wichmann, Felix and {von Luxburg}, Ulrike},
  year = {2019},
  month = jul,
  journal = {arXiv:1905.07234 [cs, stat]},
  eprint = {1905.07234},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Traditionally, psychophysical experiments are conducted by repeated measurements on a few well-trained participants under well-controlled conditions, often resulting in, if done properly, high quality data. In recent years, however, crowdsourcing platforms are becoming increasingly popular means of data collection, measuring many participants at the potential cost of obtaining data of worse quality. In this paper we study whether the use of comparison-based (ordinal) data, combined with machine learning algorithms, can boost the reliability of crowdsourcing studies for psychophysics, such that they can achieve performance close to a lab experiment. To this end, we compare three setups: simulations, a psychophysics lab experiment, and the same experiment on Amazon Mechanical Turk. All these experiments are conducted in a comparison-based setting where participants have to answer triplet questions of the form "is object x closer to y or to z?". We then use machine learning to solve the triplet prediction problem: given a subset of triplet questions with corresponding answers, we predict the answer to the remaining questions. Considering the limitations and noise on MTurk, we find that the accuracy of triplet prediction is surprisingly close---but not equal---to our lab study.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/dek/Zotero/storage/4I9W2PJP/Haghiri et al. - 2019 - Comparison-Based Framework for Psychophysics Lab .pdf;/home/dek/Zotero/storage/MB6TBE24/Haghiri et al_2019_Comparison-Based Framework for Psychophysics.pdf;/home/dek/Zotero/storage/E59HESSZ/1905.html}
}

@article{haghiriEstimationPerceptualScales2020,
  title = {Estimation of Perceptual Scales Using Ordinal Embedding},
  author = {Haghiri, Siavash and Wichmann, Felix A. and {von Luxburg}, Ulrike},
  year = {2020},
  month = sep,
  journal = {Journal of Vision},
  volume = {20},
  number = {9},
  pages = {14},
  issn = {1534-7362},
  doi = {10.1167/jov.20.9.14},
  abstract = {In this article, we address the problem of measuring and analyzing sensation, the subjective magnitude of one's experience. We do this in the context of the method of triads: The sensation of the stimulus is evaluated via relative judgments of the following form: ``Is stimulus \textbackslash (S\_i\textbackslash ) more similar to stimulus \textbackslash (S\_j\textbackslash ) or to stimulus \textbackslash (S\_k\textbackslash )?'' We propose to use ordinal embedding methods from machine learning to estimate the scaling function from the relative judgments. We review two relevant and well-known methods in psychophysics that are partially applicable in our setting: nonmetric multidimensional scaling (NMDS) and the method of maximum likelihood difference scaling (MLDS). Considering various scaling functions, we perform an extensive set of simulations to demonstrate the performance of the ordinal embedding methods. We show that in contrast to existing approaches, our ordinal embedding approach allows, first, to obtain reasonable scaling functions from comparatively few relative judgments and, second, to estimate multidimensional perceptual scales. In addition to the simulations, we analyze data from two real psychophysics experiments using ordinal embedding methods. Our results show that in the one-dimensional perceptual scale, our ordinal embedding approach works as well as MLDS, while in higher dimensions, only our ordinal embedding methods can produce a desirable scaling function. To make our methods widely accessible, we provide an R-implementation and general rules of thumb on how to use ordinal embedding in the context of psychophysics.},
  file = {/home/dek/Zotero/storage/GCZAAFB7/Haghiri et al_2020_Estimation of perceptual scales using ordinal embedding.pdf;/home/dek/Zotero/storage/UPKXA3SJ/Haghiri and Wichmann - 1 Estimation of perceptual scales using ordinal em.pdf;/home/dek/Zotero/storage/A8WUDE5K/article.html}
}

@incollection{hastieModelAssessmentSelection2009,
  title = {Model {{Assessment}} and {{Selection}}},
  booktitle = {The Elements of Statistical Learning: {{Data}} Mining, Inference, and Prediction},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  edition = {Second},
  pages = {763},
  publisher = {{Springer-Verlag}},
  abstract = {The generalization performance of a learning method relates to its prediction capability on independent test data. Assessment of this performance is extremely important in practice, since it guides the choice of learning method or model, and gives us a measure of the quality of the ultimately chosen model.}
}

@article{hebartRevealingMultidimensionalMental2020,
  title = {Revealing the Multidimensional Mental Representations of Natural Objects Underlying Human Similarity Judgements},
  author = {Hebart, Martin N. and Zheng, Charles Y. and Pereira, Francisco and Baker, Chris I.},
  year = {2020},
  month = nov,
  journal = {Nature Human Behaviour},
  volume = {4},
  number = {11},
  pages = {1173--1185},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-020-00951-3},
  abstract = {Objects can be characterized according to a vast number of possible criteria (such as animacy, shape, colour and function), but some dimensions are more useful than others for making sense of the objects around us. To identify these core dimensions of object representations, we developed a data-driven computational model of similarity judgements for real-world images of 1,854 objects. The model captured most explainable variance in similarity judgements and produced 49 highly reproducible and meaningful object dimensions that reflect various conceptual and perceptual properties of those objects. These dimensions predicted external categorization behaviour and reflected typicality judgements of those categories. Furthermore, humans can accurately rate objects along these dimensions, highlighting their interpretability and opening up a way to generate similarity estimates from object dimensions alone. Collectively, these results demonstrate that human similarity judgements can be captured by a fairly low-dimensional, interpretable embedding that generalizes to external behaviour. Hebart et al. developed a computational model of similarity judgements for 1,854 natural objects. The model accurately predicted similarity and revealed 49 interpretable dimensions that reflect both perceptual and conceptual object properties.},
  copyright = {2020 This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply},
  langid = {english},
  file = {/home/dek/Zotero/storage/4RVB87R8/Hebart et al_2020_Revealing the multidimensional mental representations of natural objects.pdf;/home/dek/Zotero/storage/GQK3FUXD/s41562-020-00951-3.html}
}

@article{henleyPsychologicalStudySemantics1969,
  title = {A Psychological Study of the Semantics of Animal Terms},
  author = {Henley, Nancy M.},
  year = {1969},
  month = apr,
  journal = {Journal of Verbal Learning and Verbal Behavior},
  volume = {8},
  number = {2},
  pages = {176--184},
  issn = {0022-5371},
  doi = {10.1016/S0022-5371(69)80058-7},
  abstract = {The semantic field of animal terms in English was investigated with five experimental techniques: free listing; pair ratings; triad ratings; verbal associations; and paired-associates learning. A set of 30 animals was scaled in the pair-rating experiment, a subset of six in one triad-rating experiment, and a subset of 12 in another triad-rating experiment. The same set of 30 animal names were stimuli for the associations. The subset of 12 were stimuli or responses in the paired-associate experiment. Results showed clear structure, with relevant dimensions of size and ferocity, for the animal terms. Furthermore, there was little effect of size of the set scaled, and different scaling techniques showed high correspondence. Different investigative methods gave highly similar clusters of animals. However, the paired-associate experiment was unsuccessful in eliciting a semantic space for animal names.},
  langid = {english},
  file = {/home/dek/Zotero/storage/AFFKC4FA/Henley - 1969 - A psychological study of the semantics of animal t.pdf;/home/dek/Zotero/storage/BP9B78PN/S0022537169800587.html}
}

@article{hochbergExtensionsMultipleTesting1995,
  title = {Extensions of Multiple Testing Procedures Based on {{Simes}}' Test},
  author = {Hochberg, Yosef and Rom, Dror},
  year = {1995},
  month = nov,
  journal = {Journal of Statistical Planning and Inference},
  volume = {48},
  number = {2},
  pages = {141--152},
  issn = {0378-3758},
  doi = {10.1016/0378-3758(95)00005-T},
  abstract = {Shaffer (J. Amer. Statist. Assoc. 81 (1986) 826\textendash 831) gave simple and more powerful modifications of Holm's (Scand. J. Statist. 6 (1979) 65\textendash 70) procedure to families of Logically Related Hypotheses (LRH). Since then, several procedures more powerful than Holm's (based on Simes (Biometrika 73 (1986) 751\textendash 754)) have been introduced, with partial or no discussion of their improvements in cases of LRH. In this article, simple and more powerful modifications of these procedures (analogous to Shaffer's modifications) for general problems of LRH are given. These modified procedures are more powerful than the modified Holm's procedure in general problems of LRH. The various modifications are demonstrated and their superiority over existing procedures is indicated for some LRH. Another extension concerns one-sided tests with normal correlated test statistics. Some analysis of the type-I error-rate associated with Simes' type procedures in this case indicates satisfactory control. A class of problems suitable for applications of a Simes' type procedure in view of the given results, is indicated.},
  langid = {english},
  keywords = {Closure,Familywise error-rate,Hierarchical hypotheses,Pairwise comparisons,Strong control},
  file = {/home/dek/Zotero/storage/Y8KRJHEI/Hochberg_Rom_1995_Extensions of multiple testing procedures based on Simes' test.pdf}
}

@article{hoConjointMeasurementGloss2008,
  title = {Conjoint Measurement of Gloss and Surface Texture},
  author = {Ho, Yun-Xian and Landy, Michael S and Maloney, Laurence T},
  year = {2008},
  journal = {Psychological science},
  volume = {19},
  number = {2},
  pages = {196--204},
  file = {/home/dek/Zotero/storage/87AIUC8T/Ho et al_2008_Conjoint measurement of gloss and surface texture.pdf}
}

@article{holmSimpleSequentiallyRejective1979,
  title = {A {{Simple Sequentially Rejective Multiple Test Procedure}}},
  author = {Holm, Sture},
  year = {1979},
  journal = {Scandinavian Journal of Statistics},
  volume = {6},
  number = {2},
  pages = {65--70},
  issn = {0303-6898},
  abstract = {This paper presents a simple and widely applicable multiple test procedure of the sequentially rejective type, i.e. hypotheses are rejected one at a time until no further rejections can be done. It is shown that the test has a prescribed level of significance protection against error of the first kind for any combination of true hypotheses. The power properties of the test and a number of possible applications are also discussed.},
  file = {/home/dek/Zotero/storage/BF4ZZ83Z/Holm_1979_A Simple Sequentially Rejective Multiple Test Procedure.pdf}
}

@article{jainFiniteSamplePrediction2016,
  ids = {jainFiniteSamplePrediction,jainFiniteSamplePredictiona},
  title = {Finite {{Sample Prediction}} and {{Recovery Bounds}} for {{Ordinal Embedding}}},
  author = {Jain, Lalit and Jamieson, Kevin G. and Nowak, Rob},
  year = {2016},
  journal = {Advances in Neural Information Processing Systems},
  volume = {29},
  eprint = {1606.07081},
  eprinttype = {arxiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {bounds,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/dek/Zotero/storage/489HFGQE/NIPS-2016-finite-sample-prediction-and-recovery-bounds-for-ordinal-embedding-Supplemental.zip;/home/dek/Zotero/storage/6XWMRBBG/Jain et al. - Finite Sample Prediction and Recovery Bounds for O.pdf;/home/dek/Zotero/storage/FWIPKKCS/Jain et al. - Finite Sample Prediction and Recovery Bounds for O.pdf;/home/dek/Zotero/storage/JM6TGB7Q/4e0d67e54ad6626e957d15b08ae128a6-Abstract.html}
}

@article{javanmardOnlineControlFalse2015,
  title = {On {{Online Control}} of {{False Discovery Rate}}},
  author = {Javanmard, Adel and Montanari, Andrea},
  year = {2015},
  month = mar,
  journal = {arXiv:1502.06197 [cs, math, stat]},
  eprint = {1502.06197},
  eprinttype = {arxiv},
  primaryclass = {cs, math, stat},
  abstract = {Multiple hypotheses testing is a core problem in statistical inference and arises in almost every scientific field. Given a sequence of null hypotheses H(n) = (H1, . . . , Hn), Benjamini and Hochberg [BH95] introduced the false discovery rate (FDR), which is the expected proportion of false positives among rejected null hypotheses, and proposed a testing procedure that controls FDR below a pre-assigned significance level. They also proposed a different criterion, called mFDR, which does not control a property of the realized set of tests; rather it controls the ratio of expected number of false discoveries to the expected number of discoveries.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Applications,Statistics - Methodology},
  file = {/home/dek/Zotero/storage/T3FRVZK9/Javanmard and Montanari - 2015 - On Online Control of False Discovery Rate.pdf}
}

@misc{JohannesHölscher,
  title = {Johannes {{H\"olscher}}},
  howpublished = {https://3.basecamp.com/3176329/circles/24298808},
  file = {/home/dek/Zotero/storage/5AQ6FC36/24298808.html}
}

@article{kimPerceptionGlossDepends2011,
  title = {The Perception of Gloss Depends on Highlight Congruence with Surface Shading},
  author = {Kim, Juno and Marlow, Phillip and Anderson, Barton L.},
  year = {2011},
  month = aug,
  journal = {Journal of Vision},
  volume = {11},
  number = {9},
  pages = {4},
  issn = {1534-7362},
  doi = {10.1167/11.9.4},
  abstract = {Studies have shown that displacing specular highlights from their natural locations in images reduces perceived surface gloss. Here, we assessed the extent to which perceived gloss depends on congruence in the position and orientation of specular highlights relative to surface shape and the diffuse shading from which surface shape is recovered. The position and orientation congruence of specular highlights with diffuse shading was altered while preserving their compatibility with physical surface shape (Experiment 1). We found that perceived gloss diminished as the position of highlights became incompatible wit h the surface's global diffuse shading maxima. In a subsequent experiment, we constrained highlight proximity near the global luminance maxima in diffuse shading. When we disrupted the consistency in the local position and orientation of specular highlights with respect to the diffuse shading and local surface meso-structure, a decline in perceived gloss was still observed (Experiment 2). This decline in perceived gloss caused by misaligning the positions and orientations of specular highlights relative to diffuse surface shading could not be explained by differences in orientation fields alone (Experiments 3 and 4). These results suggest the visual system assesses both position and orientation congruence between specular highlights and diffuse shading to estimate surface gloss.},
  file = {/home/dek/Zotero/storage/GFUKV7YT/article.html}
}

@inproceedings{kleindessnerDimensionalityEstimationDistances2015,
  title = {Dimensionality Estimation without Distances},
  booktitle = {Artificial {{Intelligence}} and {{Statistics}}},
  author = {Kleindessner, Matth{\"a}us and Luxburg, Ulrike},
  year = {2015},
  month = feb,
  pages = {471--479},
  publisher = {{PMLR}},
  issn = {1938-7228},
  abstract = {While existing methods for estimating the intrinsic dimension of datasets require to know distances between data points, we consider a situation where one has considerably less information. Given a...},
  langid = {english},
  file = {/home/dek/Zotero/storage/HQIV3ZJE/Kleindessner_Luxburg_2015_Dimensionality estimation without distances.pdf;/home/dek/Zotero/storage/XIG8SRJA/kleindessner15.html}
}

@inproceedings{kleindessnerKernelFunctionsBased2017,
  title = {Kernel Functions Based on Triplet Comparisons},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Kleindessner, Matth{\"a}us and {von Luxburg}, Ulrike},
  editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  year = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  file = {/home/dek/Zotero/storage/48YUMUE4/Kleindessner - Kernel functions based on triplet comparisons.pdf}
}

@article{kleindessnerLensDepthFunction2017,
  title = {Lens {{Depth Function}} and K-{{Relative Neighborhood Graph}}: {{Versatile Tools}} for {{Ordinal Data Analysis}}},
  shorttitle = {Lens {{Depth Function}} and K-{{Relative Neighborhood Graph}}},
  author = {Kleindessner, Matth{\"a}us and von Luxburg, Ulrike},
  year = {2017},
  journal = {Journal of Machine Learning Research},
  volume = {18},
  number = {58},
  pages = {1--52},
  issn = {1533-7928},
  langid = {english},
  file = {/home/dek/Zotero/storage/PY84ZFD7/Kleindessner_Luxburg_2017_Lens Depth Function and k-Relative Neighborhood Graph.pdf;/home/dek/Zotero/storage/BXJE5WLH/16-061.html}
}

@inproceedings{kleindessnerUniquenessOrdinalEmbedding2014,
  title = {Uniqueness of {{Ordinal Embedding}}},
  booktitle = {Proceedings of {{The}} 27th {{Conference}} on {{Learning Theory}}},
  author = {Kleindessner, Matth{\"a}us and Luxburg, Ulrike},
  year = {2014},
  month = may,
  pages = {40--67},
  publisher = {{PMLR}},
  issn = {1938-7228},
  abstract = {Ordinal embedding refers to the following problem: all we know about an unknown set of 	 		points x\_1,\textbackslash ldots, x\_n {$\in\backslash$}mathbbR\^d are ordinal constraints of the form \textbackslash |x\_i - x\_j\textbackslash | {$<$} \textbackslash |x\_k - x\_l\textbackslash |; the task is to construct a realization y\_1,\textbackslash ldots, y\_n {$\in\backslash$}mathbbR\^d that preserves these ordinal constraints. It has been conjectured since the 1960ies that upon knowledge of all ordinal constraints a large but finite set of points can be approximately reconstructed up to a similarity transformation. The main result of our paper is a formal proof of this conjecture.},
  langid = {english},
  file = {/home/dek/Zotero/storage/EM39PM94/Kleindessner_Luxburg_2014_Uniqueness of Ordinal Embedding.pdf}
}

@book{knoblauchModelingPsychophysicalData2012,
  title = {Modeling {{Psychophysical Data}} in {{R}}},
  author = {Knoblauch, Kenneth and Maloney, Laurence T.},
  year = {2012},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-4475-6},
  isbn = {978-1-4614-4474-9 978-1-4614-4475-6},
  langid = {english},
  file = {/home/dek/Zotero/storage/X2HWU5XM/Knoblauch und Maloney - 2012 - Modeling Psychophysical Data in R.pdf}
}

@article{koenderinkEidolonsNovelStimuli2017,
  title = {Eidolons: {{Novel}} Stimuli for Vision Research},
  shorttitle = {Eidolons},
  author = {Koenderink, Jan and Valsecchi, Matteo and van Doorn, Andrea and Wagemans, Johan and Gegenfurtner, Karl},
  year = {2017},
  month = feb,
  journal = {Journal of Vision},
  volume = {17},
  number = {2},
  pages = {7--7},
  publisher = {{The Association for Research in Vision and Ophthalmology}},
  issn = {1534-7362},
  doi = {10.1167/17.2.7},
  langid = {english},
  file = {/home/dek/Zotero/storage/74JQ9XVQ/Koenderink et al. - 2017 - Eidolons Novel stimuli for vision research.pdf;/home/dek/Zotero/storage/LN6UCCU5/article.html}
}

@article{kruskalMultidimensionalScalingOptimizing1964,
  title = {Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis},
  author = {Kruskal, J. B.},
  year = {1964},
  month = mar,
  journal = {Psychometrika},
  volume = {29},
  number = {1},
  pages = {1--27},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02289565},
  langid = {english},
  file = {/home/dek/Zotero/storage/9UK9F59C/Kruskal - 1964 - Multidimensional scaling by optimizing goodness of.pdf}
}

@article{kruskalNonmetricMultidimensionalScaling1964,
  title = {Nonmetric Multidimensional Scaling: {{A}} Numerical Method},
  shorttitle = {Nonmetric Multidimensional Scaling},
  author = {Kruskal, J. B.},
  year = {1964},
  month = jun,
  journal = {Psychometrika},
  volume = {29},
  number = {2},
  pages = {115--129},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02289694},
  langid = {english},
  file = {/home/dek/Zotero/storage/8IN5Q2DT/Kruskal - 1964 - Nonmetric multidimensional scaling A numerical me.pdf}
}

@article{lagunasSimilarityMeasureMaterial2019,
  title = {A {{Similarity Measure}} for {{Material Appearance}}},
  author = {Lagunas, Manuel and Malpica, Sandra and Serrano, Ana and Garces, Elena and Gutierrez, Diego and Masia, Belen},
  year = {2019},
  month = jul,
  journal = {ACM Transactions on Graphics},
  volume = {38},
  number = {4},
  eprint = {1905.01562},
  eprinttype = {arxiv},
  pages = {1--12},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3306346.3323036},
  abstract = {We present a model to measure the similarity in appearance between different materials, which correlates with human similarity judgments. We first create a database of 9,000 rendered images depicting objects with varying materials, shape and illumination. We then gather data on perceived similarity from crowdsourced experiments; our analysis of over 114,840 answers suggests that indeed a shared perception of appearance similarity exists. We feed this data to a deep learning architecture with a novel loss function, which learns a feature space for materials that correlates with such perceived appearance similarity. Our evaluation shows that our model outperforms existing metrics. Last, we demonstrate several applications enabled by our metric, including appearance-based search for material suggestions, database visualization, clustering and summarization, and gamut mapping.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning},
  file = {/home/dek/Zotero/storage/BC657JSI/Lagunas et al. - 2019 - A Similarity Measure for Material Appearance.pdf}
}

@article{logvinenkoProximityStructureAchromatic2006,
  title = {The Proximity Structure of Achromatic Surface Colors and the Impossibility of Asymmetric Lightness Matching},
  author = {Logvinenko, Alexander D. and Maloney, Laurence T.},
  year = {2006},
  month = jan,
  journal = {Perception \& Psychophysics},
  volume = {68},
  number = {1},
  pages = {76--83},
  issn = {0031-5117, 1532-5962},
  doi = {10.3758/BF03193657},
  langid = {english},
  file = {/home/dek/Zotero/storage/KJBZEGID/Logvinenko_Maloney_2006_The proximity structure of achromatic surface colors and the impossibility of.pdf}
}

@article{lohausUncertaintyEstimatesOrdinal2019,
  title = {Uncertainty {{Estimates}} for {{Ordinal Embeddings}}},
  author = {Lohaus, Michael and Hennig, Philipp and {von Luxburg}, Ulrike},
  year = {2019},
  month = jun,
  journal = {arXiv:1906.11655 [cs, stat]},
  eprint = {1906.11655},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {To investigate objects without a describable notion of distance, one can gather ordinal information by asking triplet comparisons of the form ``Is object x closer to y or is x closer to z?'' In order to learn from such data, the objects are typically embedded in a Euclidean space while satisfying as many triplet comparisons as possible. In this paper, we introduce empirical uncertainty estimates for standard embedding algorithms when few noisy triplets are available, using a bootstrap and a Bayesian approach. In particular, simulations show that these estimates are well calibrated and can serve to select embedding parameters or to quantify uncertainty in scientific applications.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/dek/Zotero/storage/EB3N3GSZ/Lohaus et al. - 2019 - Uncertainty Estimates for Ordinal Embeddings.pdf}
}

@article{loveSimilarityWindowDimensions2021,
  title = {Similarity as a {{Window}} on the {{Dimensions}} of {{Object Representation}}},
  author = {Love, Bradley C. and Roads, Brett D.},
  year = {2021},
  month = feb,
  journal = {Trends in Cognitive Sciences},
  volume = {25},
  number = {2},
  pages = {94--96},
  issn = {1364-6613, 1879-307X},
  doi = {10.1016/j.tics.2020.12.003},
  langid = {english},
  pmid = {33358386},
  keywords = {big data,embedding spaces,knowledge representation,multidimensional scaling,similarity},
  file = {/home/dek/Zotero/storage/G8SX56YR/S1364-6613(20)30300-4.html}
}

@article{mackKsampleRankTests1981,
  title = {K-Sample Rank Tests for Umbrella Alternatives},
  author = {Mack, Gregory A and Wolfe, Douglas A},
  year = {1981},
  journal = {Journal of the American Statistical Association},
  volume = {76},
  number = {373},
  pages = {175--181},
  publisher = {{Taylor \& Francis}},
  file = {/home/dek/Zotero/storage/D63857H7/Mack and Wolfe - 2021 - K-Sample Rank Tests for Umbrella Alternatives.pdf}
}

@article{maloneyMaximumLikelihoodDifference2003,
  title = {Maximum Likelihood Difference Scaling},
  author = {Maloney, Laurence T and Yang, Joong Nam},
  year = {2003},
  journal = {Journal of Vision},
  volume = {3},
  number = {8},
  pages = {5--5},
  file = {/home/dek/Zotero/storage/73PNT2BT/Maloney and Yang - 2003 - Maximum likelihood difference scaling.pdf}
}

@article{marlowPerceptionMisperceptionSpecular2012,
  title = {The {{Perception}} and {{Misperception}} of {{Specular Surface Reflectance}}},
  author = {Marlow, Phillip J. and Kim, Juno and Anderson, Barton L.},
  year = {2012},
  month = oct,
  journal = {Current Biology},
  volume = {22},
  number = {20},
  pages = {1909--1913},
  publisher = {{Elsevier}},
  issn = {0960-9822},
  doi = {10.1016/j.cub.2012.08.009},
  langid = {english},
  pmid = {22959347},
  file = {/home/dek/Zotero/storage/R3R5IYNH/Marlow et al_2012_The Perception and Misperception of Specular Surface Reflectance.pdf;/home/dek/Zotero/storage/IN65SKKI/S0960-9822(12)00937-2.html}
}

@article{marlowPerceptionMisperceptionSurface2017,
  title = {Perception and Misperception of Surface Opacity},
  author = {Marlow, Phillip J. and Kim, Juno and Anderson, Barton L.},
  year = {2017},
  month = dec,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {114},
  number = {52},
  pages = {13840--13845},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1711416115},
  abstract = {A fundamental problem in extracting scene structure is distinguishing different physical sources of image structure. Light reflected by an opaque surface covaries with local surface orientation, whereas light transported through the body of a translucent material does not. This suggests the possibility that the visual system may use the covariation of local surface orientation and intensity as a cue to the opacity of surfaces. We tested this hypothesis by manipulating the contrast of luminance gradients and the surface geometries to which they belonged and assessed how these manipulations affected the perception of surface opacity/translucency. We show that (i) identical luminance gradients can appear either translucent or opaque depending on the relationship between luminance and perceived 3D surface orientation, (ii) illusory percepts of translucency can be induced by embedding opaque surfaces in diffuse light fields that eliminate the covariation between surface orientation and intensity, and (iii) illusory percepts of opacity can be generated when transparent materials are embedded in a light field that generates images where surface orientation and intensity covary. Our results provide insight into how the visual system distinguishes opaque surfaces and light-permeable materials and why discrepancies arise between the perception and physics of opacity and translucency. These results suggest that the most significant information used to compute the perceived opacity and translucency of surfaces arise at a level of representation where 3D shape is made explicit.},
  chapter = {Biological Sciences},
  copyright = {\textcopyright{} 2017 . http://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
  langid = {english},
  pmid = {29229812},
  keywords = {3D shape,material perception,reflectance,translucency,visual perception},
  file = {/home/dek/Zotero/storage/54B5U8FF/Marlow et al_2017_Perception and misperception of surface opacity.pdf;/home/dek/Zotero/storage/AHSDEWSG/13840.html}
}

@article{marlowRoleBrightnessOrientation2011,
  title = {The Role of Brightness and Orientation Congruence in the Perception of Surface Gloss},
  author = {Marlow, Phillip and Kim, Juno and Anderson, Barton L.},
  year = {2011},
  month = aug,
  journal = {Journal of Vision},
  volume = {11},
  number = {9},
  pages = {16},
  issn = {1534-7362},
  doi = {10.1167/11.9.16},
  abstract = {The perception of surface gloss depends on specular highlights but little is understood about how the visual system distinguishes specular highlights from other luminance maxima generated by variations in pigmentation or illumination. It has been argued that diffuse shading gradients provide information for identifying specular highlights. Specular highlights typically share the orientation of the diffuse shading locally. Specular highlights are typically proximal to the brightest region of the diffuse shading locally. We compared the contributions of these two relationships to perceived gloss. Highlight orientation relative to the diffuse shading was varied by rotating highlights. Highlight distance from the brightest region of the diffuse shading was varied by translating highlights in displays that preserved the orientations of highlights relative to their surrounds. Both manipulations reduced perceived gloss. Rotations reduced perceived gloss more than translations, even though translations displaced highlights into darker regions than rotations. The same reductions in perceived gloss occurred when highlights were matched in perceived contrast across conditions (Experiment 2b). The results provide evidence that the perception of gloss depends on highlight distance from the luminance maxima of the surrounding intensity gradient (brightness congruence) in addition to the shared orientation of highlights with their surrounds (orientation congruence).},
  file = {/home/dek/Zotero/storage/UQJDF5FE/article.html}
}

@article{meisterDimensionalityOdorSpace2015,
  title = {On the Dimensionality of Odor Space},
  author = {Meister, Markus},
  editor = {Borst, Alexander},
  year = {2015},
  month = jul,
  journal = {eLife},
  volume = {4},
  pages = {e07865},
  issn = {2050-084X},
  doi = {10.7554/eLife.07865},
  abstract = {There is great interest in understanding human olfactory experience from a principled and quantitative standpoint. The comparison is often made to color vision, where a solid framework with a three-dimensional perceptual space enabled a rigorous search for the underlying neural pathways, and the technological development of lifelike color display devices. A recent, highly publicized report claims that humans can discriminate at least 1 trillion odors, which exceeds by many orders of magnitude the known capabilities of color discrimination. This claim is wrong. I show that the failure lies in the mathematical method used to infer the size of odor space from a limited experimental sample. Further analysis focuses on establishing how many dimensions the perceptual odor space has. I explore the dimensionality of physical, neural, and perceptual spaces, drawing on results from bacteria to humans, and propose some experimental approaches to better estimate the number of discriminable odors.},
  keywords = {computation,olfaction,perception},
  file = {/home/dek/Zotero/storage/SYV8F5R2/Meister_2015_On the dimensionality of odor space.pdf}
}

@article{mooneySpecularImageStructure2014,
  title = {Specular {{Image Structure Modulates}} the {{Perception}} of {{Three-Dimensional Shape}}},
  author = {Mooney, Scott W. J. and Anderson, Barton L.},
  year = {2014},
  month = nov,
  journal = {Current Biology},
  volume = {24},
  number = {22},
  pages = {2737--2742},
  publisher = {{Elsevier}},
  issn = {0960-9822},
  doi = {10.1016/j.cub.2014.09.074},
  langid = {english},
  pmid = {25455034},
  file = {/home/dek/Zotero/storage/JQSBGICR/Mooney_Anderson_2014_Specular Image Structure Modulates the Perception of Three-Dimensional Shape.pdf;/home/dek/Zotero/storage/ZRD62BHM/S0960-9822(14)01270-6.html}
}

@article{nadeauInferenceGeneralizationError2003,
  ids = {nadeauInferenceGeneralizationError},
  title = {Inference for the {{Generalization Error}}},
  author = {Nadeau, Claude and Bengio, Yoshua},
  year = {2003},
  month = sep,
  journal = {Machine Learning},
  volume = {52},
  number = {3},
  pages = {239--281},
  issn = {1573-0565},
  doi = {10.1023/A:1024068626366},
  abstract = {In order to compare learning algorithms, experimental results reported in the machine learning literature often use statistical tests of significance to support the claim that a new learning algorithm generalizes better. Such tests should take into account the variability due to the choice of training set and not only that due to the test examples, as is often the case. This could lead to gross underestimation of the variance of the cross-validation estimator, and to the wrong conclusion that the new algorithm is significantly better when it is not. We perform a theoretical investigation of the variance of a variant of the cross-validation estimator of the generalization error that takes into account the variability due to the randomness of the training set as well as test examples. Our analysis shows that all the variance estimators that are based only on the results of the cross-validation experiment must be biased. This analysis allows us to propose new estimators of this variance. We show, via simulations, that tests of hypothesis about the generalization error using those new variance estimators have better properties than tests involving variance estimators currently in use and listed in Dietterich (1998). In particular, the new tests have correct size and good power. That is, the new tests do not reject the null hypothesis too often when the hypothesis is true, but they tend to frequently reject the null hypothesis when the latter is false.},
  langid = {english},
  file = {/home/dek/Zotero/storage/8C23RAIV/Nadeau_Bengio_2003_Inference for the Generalization Error.pdf;/home/dek/Zotero/storage/LY3LCUAW/Nadeau and Bengio - Inference for the Generalization Error.pdf}
}

@article{ohBayesianMultidimensionalScaling2001,
  title = {Bayesian {{Multidimensional Scaling}} and {{Choice}} of {{Dimension}}},
  author = {Oh, Man-Suk and Raftery, Adrian E.},
  year = {2001},
  journal = {Journal of the American Statistical Association},
  volume = {96},
  number = {455},
  pages = {1031--1044},
  publisher = {{[American Statistical Association, Taylor \& Francis, Ltd.]}},
  issn = {0162-1459},
  abstract = {Multidimensional scaling is widely used to handle data that consist of similarity or dissimilarity measures between pairs of objects. We deal with two major problems in metric multidimensional scaling-configuration of objects and determination of the dimension of object configuration-within a Bayesian framework. A Markov chain Monte Carlo algorithm is proposed for object configuration, along with a simple Bayesian criterion, called MDSIC, for choosing their dimension. Simulation results are presented, as are real data. Our method provides better results than does classical multidimensional scaling and ALSCAL for object configuration, and MDSIC seems to work well for dimension choice in the examples considered.}
}

@article{paulunShapeMotionOptical2017,
  title = {Shape, Motion, and Optical Cues to Stiffness of Elastic Objects},
  author = {Paulun, Vivian C. and Schmidt, Filipp and {van Assen}, Jan Jaap R. and Fleming, Roland W.},
  year = {2017},
  month = jan,
  journal = {Journal of Vision},
  volume = {17},
  number = {1},
  pages = {20},
  issn = {1534-7362},
  doi = {10.1167/17.1.20},
  abstract = {Nonrigid materials, such as jelly, rubber, or sponge move and deform in distinctive ways depending on their stiffness. Which cues do we use to infer stiffness? We simulated cubes of varying stiffness and optical appearance (e.g., wood, metal, wax, jelly) being subjected to two kinds of deformation: (a) a rigid cylinder pushing downwards into the cube to various extents (shape change, but little motion: shape dominant), (b) a rigid cylinder retracting rapidly from the cube (same initial shapes, differences in motion: motion dominant). Observers rated the apparent softness/hardness of the cubes. In the shape-dominant condition, ratings mainly depended on how deeply the rod penetrated the cube and were almost unaffected by the cube's intrinsic physical properties. In contrast, in the motion-dominant condition, ratings varied systematically with the cube's intrinsic stiffness, and were less influenced by the extent of the perturbation. We find that both results are well predicted by the absolute magnitude of deformation, suggesting that when asked to judge stiffness, observers resort to simple heuristics based on the amount of deformation. Softness ratings for static, unperturbed cubes varied substantially and systematically depending on the optical properties. However, when animated, the ratings were again dominated by the extent of the deformation, and the effect of optical appearance was negligible. Together, our results suggest that to estimate stiffness, the visual system strongly relies on measures of the extent to which an object changes shape in response to forces.},
  file = {/home/dek/Zotero/storage/M5G78ABH/Paulun et al. - 2017 - Shape, motion, and optical cues to stiffness of el.pdf}
}

@article{perrotNearOptimalComparisonBased2020,
  title = {Near-{{Optimal Comparison Based Clustering}}},
  author = {Perrot, Micha{\"e}l and Esser, Pascal Mattia and Ghoshdastidar, Debarghya},
  year = {2020},
  month = oct,
  journal = {arXiv:2010.03918 [cs, stat]},
  eprint = {2010.03918},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {The goal of clustering is to group similar objects into meaningful partitions. This process is well understood when an explicit similarity measure between the objects is given. However, far less is known when this information is not readily available and, instead, one only observes ordinal comparisons such as ``object i is more similar to j than to k.'' In this paper, we tackle this problem using a two-step procedure: we estimate a pairwise similarity matrix from the comparisons before using a clustering method based on semi-definite programming (SDP). We theoretically show that our approach can exactly recover a planted clustering using a near-optimal number of passive comparisons. We empirically validate our theoretical findings and demonstrate the good behaviour of our method on real data.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/dek/Zotero/storage/8MEJS8B2/Perrot et al. - 2020 - Near-Optimal Comparison Based Clustering.pdf}
}

@article{radonjic2019relative,
  title = {The Relative Contribution of Color and Material in Object Selection},
  author = {Radonji{\'c}, Ana and Cottaris, Nicolas P and Brainard, David H},
  year = {2019},
  journal = {PLoS computational biology},
  volume = {15},
  number = {4},
  pages = {e1006950},
  publisher = {{Public Library of Science San Francisco, CA USA}},
  file = {/home/dek/Zotero/storage/P32V56C4/Radonjić et al. - 2019 - The relative contribution of color and material in.pdf}
}

@article{roadsEnrichingImageNetHuman2020,
  title = {Enriching {{ImageNet}} with {{Human Similarity Judgments}} and {{Psychological Embeddings}}},
  author = {Roads, Brett D. and Love, Bradley C.},
  year = {2020},
  month = nov,
  journal = {arXiv:2011.11015 [cs]},
  eprint = {2011.11015},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Advances in object recognition flourished in part because of the availability of high-quality datasets and associated benchmarks. However, these benchmarks\textemdash such as ILSVRC\textemdash are relatively task-specific, focusing predominately on predicting class labels. We introduce a publiclyavailable dataset that embodies the task-general capabilities of human perception and reasoning. The Human Similarity Judgments extension to ImageNet (ImageNet-HSJ) is composed of human similarity judgments that supplement the ILSVRC validation set. The new dataset supports a range of task and performance metrics, including the evaluation of unsupervised learning algorithms. We demonstrate two methods of assessment: using the similarity judgments directly and using a psychological embedding trained on the similarity judgments. This embedding space contains an order of magnitude more points (i.e., images) than previous efforts based on human judgments. Scaling to the full 50,000 image set was made possible through a selective sampling process that used variational Bayesian inference and model ensembles to sample aspects of the embedding space that were most uncertain. This methodological innovation not only enables scaling, but should also improve the quality of solutions by focusing sampling where it is needed. To demonstrate the utility of ImageNet-HSJ, we used the similarity ratings and the embedding space to evaluate how well several popular models conform to human similarity judgments. One finding is that more complex models that perform better on task-specific benchmarks do not better conform to human semantic judgments. In addition to the human similarity judgments, pre-trained psychological embeddings and code for inferring variational embeddings are made publicly available. Collectively, ImageNet-HSJ assets support the appraisal of internal representations and the development of more human-like models.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/dek/Zotero/storage/J4WGA862/Roads und Love - 2020 - Enriching ImageNet with Human Similarity Judgments.pdf}
}

@inproceedings{roadsEnrichingImageNetHuman2021,
  title = {Enriching {{ImageNet}} with {{Human Similarity Judgments}} and {{Psychological Embeddings}}},
  booktitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Roads, Brett D. and Love, Bradley C.},
  year = {2021},
  month = jun,
  pages = {3546--3556},
  issn = {2575-7075},
  doi = {10.1109/CVPR46437.2021.00355},
  abstract = {Advances in supervised learning approaches to object recognition flourished in part because of the availability of high-quality datasets and associated benchmarks. However, these benchmarks\textemdash such as ILSVRC\textemdash are relatively task-specific, focusing predominately on predicting class labels. We introduce a publicly-available dataset that embodies the task-general capabilities of human perception and reasoning. The Human Similarity Judgments extension to ImageNet (ImageNet-HSJ) is composed of a large set of human similarity judgments that supplements the existing ILSVRC validation set. The new dataset supports a range of task and performance metrics, including evaluation of unsupervised algorithms. We demonstrate two methods of assessment: using the similarity judgments directly and using a psychological embedding trained on the similarity judgments. This embedding space contains an order of magnitude more points (i.e., images) than previous efforts based on human judgments. We were able to scale to the full 50,000 image ILSVRC validation set through a selective sampling process that used variational Bayesian inference and model ensembles to sample aspects of the embedding space that were most uncertain. To demonstrate the utility of ImageNet-HSJ, we used the similarity ratings and the embedding space to evaluate how well several popular models conform to human similarity judgments. One finding is that the more complex models that perform better on task-specific benchmarks do not better conform to human semantic judgments. In addition to the human similarity judgments, pre-trained psychological embeddings and code for inferring variational embeddings are made publicly available. ImageNet-HSJ supports the appraisal of internal representations and the development of more humanlike models.},
  keywords = {Benchmark testing,Computer vision,Focusing,Measurement,Psychology,Semantics,Supervised learning},
  file = {/home/dek/Zotero/storage/QIIWNJQ4/Roads and Love - 2021 - Enriching ImageNet with Human Similarity Judgments.pdf;/home/dek/Zotero/storage/GZA43IFP/9578028.html}
}

@article{roadsObtainingPsychologicalEmbeddings2019,
  title = {Obtaining Psychological Embeddings through Joint Kernel and Metric Learning},
  author = {Roads, Brett D. and Mozer, Michael C.},
  year = {2019},
  month = oct,
  journal = {Behavior Research Methods},
  volume = {51},
  number = {5},
  pages = {2180--2193},
  issn = {1554-3528},
  doi = {10.3758/s13428-019-01285-3},
  abstract = {Psychological embeddings provide a powerful formalism for characterizing human-perceived similarity among members of a stimulus set. Obtaining high-quality embeddings can be costly due to algorithm design, software deployment, and participant compensation. This work aims to advance state-of-the-art embedding techniques and provide a comprehensive software package that makes obtaining high-quality psychological embeddings both easy and relatively efficient. Contributions are made on four fronts. First, the embedding procedure allows multiple trial configurations (e.g., triplets) to be used for collecting similarity judgments from participants. For example, trials can be configured to collect triplet comparisons or to sort items into groups. Second, a likelihood model is provided for three classes of similarity kernels allowing users to easily infer the parameters of their preferred model using gradient descent. Third, an active selection algorithm is provided that makes data collection more efficient by proposing comparisons that provide the strongest constraints on the embedding. Fourth, the likelihood model allows the specification of group-specific attention weight parameters. A series of experiments are included to highlight each of these contributions and their impact on converging to a high-quality embedding. Collectively, these incremental improvements provide a powerful and complete set of tools for inferring psychological embeddings. The relevant tools are available as the Python package PsiZ, which can be cloned from GitHub (https://github.com/roads/psiz).},
  langid = {english},
  file = {/home/dek/Zotero/storage/WQZYJI9N/Roads_Mozer_2019_Obtaining psychological embeddings through joint kernel and metric learning.pdf}
}

@article{rosasObservationsEffectsSlant2004,
  title = {Some Observations on the Effects of Slant and Texture Type on Slant-from-Texture},
  author = {Rosas, Pedro and Wichmann, Felix A and Wagemans, Johan},
  year = {2004},
  month = jun,
  journal = {Vision Research},
  volume = {44},
  number = {13},
  pages = {1511--1535},
  issn = {0042-6989},
  doi = {10.1016/j.visres.2004.01.013},
  abstract = {We measure the performance of five subjects in a two-alternative-forced-choice slant-discrimination task for differently textured planes. As textures we used uniform lattices, randomly displaced lattices, circles (polka dots), Voronoi tessellations, plaids, 1/f noise, ``coherent'' noise and a leopard skin-like texture. Our results show: (1) Improving performance with larger slants for all textures, (2) and some cases of ``non-symmetrical'' performance around a particular orientation. (3) For orientations sufficiently slanted, the different textures do not elicit major differences in performance, (4) while for orientations closer to the vertical plane there are marked differences among them. (5) These differences allow a rank-order of textures to be formed according to their ``helpfulness''\textendash\textendash that is, how easy the discrimination task is when a particular texture is mapped on the plane. Polka dots tend to allow the best slant discrimination performance, noise patterns the worst. Two additional experiments were conducted to test the generality of the obtained rank-order. First, the tilt of the planes was rotated by 90\textdegree. Second, the task was changed to a slant report task via probe adjustment. The results of both control experiments confirmed the texture rank-order previously obtained. We then test a number of spatial-frequency-based slant-from-texture models and discuss their shortcomings in explaining our rank-order. Finally, we comment on the importance of these results for depth-perception research in general, and in particular the implications our results have for studies of cue combination (sensor fusion) using texture as one of the cues involved.},
  langid = {english},
  keywords = {Slant,Slant-from-texture,Texture},
  file = {/home/dek/Zotero/storage/F3SEBM59/Rosas et al. - 2004 - Some observations on the effects of slant and text.pdf}
}

@article{rosasTextureHapticCues2005,
  title = {Texture and Haptic Cues in Slant Discrimination: Reliability-Based Cue Weighting without Statistically Optimal Cue Combination},
  shorttitle = {Texture and Haptic Cues in Slant Discrimination},
  author = {Rosas, Pedro and Wagemans, Johan and Ernst, Marc O. and Wichmann, Felix A.},
  year = {2005},
  month = may,
  journal = {JOSA A},
  volume = {22},
  number = {5},
  pages = {801--809},
  publisher = {{Optical Society of America}},
  issn = {1520-8532},
  doi = {10.1364/JOSAA.22.000801},
  abstract = {A number of models of depth\textendash cue combination suggest that the final depth percept results from a weighted average of independent depth estimates based on the different cues available. The weight of each cue in such an average is thought to depend on the reliability of each cue. In principle, such a depth estimation could be statistically optimal in the sense of producing the minimum-variance unbiased estimator that can be constructed from the available information. Here we test such models by using visual and haptic depth information. Different texture types produce differences in slant-discrimination performance, thus providing a means for testing a reliability-sensitive cue-combination model with texture as one of the cues to slant. Our results show that the weights for the cues were generally sensitive to their reliability but fell short of statistically optimal combination\textemdash we find reliability-based reweighting but not statistically optimal cue combination.},
  copyright = {\textcopyright{} 2005 Optical Society of America},
  langid = {english},
  keywords = {Adaptive optics,Fusion,Sensors,Vision modeling,Visual optics,Visual system},
  file = {/home/dek/Zotero/storage/Q7FSNY3S/Rosas et al. - 2005 - Texture and haptic cues in slant discrimination r.pdf;/home/dek/Zotero/storage/UR78JSD4/abstract.html}
}

@article{rosasTextureObjectMotion2007,
  title = {Texture and Object Motion in Slant Discrimination: {{Failure}} of Reliability-Based Weighting of Cues May Be Evidence for Strong Fusion},
  shorttitle = {Texture and Object Motion in Slant Discrimination},
  author = {Rosas, Pedro and Wichmann, Felix A. and Wagemans, Johan},
  year = {2007},
  month = apr,
  journal = {Journal of Vision},
  volume = {7},
  number = {6},
  pages = {3},
  issn = {1534-7362},
  doi = {10.1167/7.6.3},
  abstract = {Different types of texture produce differences in slant-discrimination performance (P. Rosas, F. A. Wichmann, \&amp; J. Wagemans, 2004). Under the assumption that the visual system is sensitive to the reliability of different depth cues (M. O. Ernst \&amp; M. S. Banks, 2002; L. T. Maloney \&amp; M. S. Landy, 1989), it follows that the texture type should affect the influence of the texture cue in depth-cue combination. We tested this prediction by combining different texture types with object motion in a slant-discrimination task in two experiments. First, we used consistent cues to observe whether our subjects behaved as linearly combining independent estimates from texture and motion in a statistical optimal fashion (M. O. Ernst \&amp; M. S. Banks, 2002). Only 4\% of our results were consistent with such an optimal combination of uncorrelated estimates, whereas about 46\% of the data were consistent with an optimal combination of correlated estimates from cues. Second, we measured the weights for the texture and motion cues using perturbation analysis. The results showed a large influence of the motion cue and an increasing weight for the texture cue for larger slants. However, in general, the texture weights did not follow the reliability of the textures. Finally, we fitted the correlation coefficients of estimates individually for each texture, motion condition, and observer. This allows us to fit our data from both experiments to an optimal cue combination model with correlated estimates, but inspection of the fitted parameters shows no clear, psychophysically interpretable pattern. Furthermore, the fitted motion thresholds as a function of texture type are correlated with the slant thresholds as a function of texture type. One interpretation of such a finding is a strong coupling of cues.},
  file = {/home/dek/Zotero/storage/3X7RCRML/Rosas et al. - 2007 - Texture and object motion in slant discrimination.pdf;/home/dek/Zotero/storage/KLW9MGCQ/article.html}
}

@article{schmidPerceptualDimensionsUnderlying2017,
  title = {Perceptual Dimensions Underlying Lightness Perception in Homogeneous Center-Surround Displays},
  author = {Schmid, Alexandra C. and Anderson, Barton L.},
  year = {2017},
  month = mar,
  journal = {Journal of Vision},
  volume = {17},
  number = {2},
  pages = {6},
  issn = {1534-7362},
  doi = {10.1167/17.2.6},
  abstract = {Lightness judgments of targets embedded in a homogeneous surround exhibit abrupt steps in perceived lightness at points at which the targets transition from being increments to decrements. This ``crispening effect'' and the general difficulty of matching low-contrast targets embedded in homogeneous surrounds suggest that a second perceptual dimension in addition to lightness may contribute to the appearance of test patches in these displays. The present study explicitly tested whether two dimensions (lightness and transmittance) could lead to more satisfactory matches than lightness alone in an asymmetric matching task. We also examined whether transmittance matches were more strongly associated with task instructions that had observers match perceived transparency or the perceived edge contrast of the target relative to the surround. We found that matching target lightness in a homogeneous display to that in a textured or rocky display required varying both lightness and transmittance of the test patch on the textured display to obtain the most satisfactory matches. However, observers primarily varied transmittance when instructed to match the perceived contrast of targets against homogeneous surrounds, but not when instructed to match the amount of transparency perceived in the displays. The results suggest that perceived target\textendash surround edge contrast differs between homogeneous and textured displays. Varying the midlevel property of transparency in textured displays provides a natural means for equating both target lightness and the unique appearance of the edge contrast in homogeneous displays.},
  keywords = {important},
  file = {/home/dek/Zotero/storage/8HT48XVN/Schmid_Anderson_2017_Perceptual dimensions underlying lightness perception in homogeneous.pdf}
}

@article{schmidtInferringStiffnessUnfamiliar2017,
  title = {Inferring the Stiffness of Unfamiliar Objects from Optical, Shape, and Motion Cues},
  author = {Schmidt, Filipp and Paulun, Vivian C. and {van Assen}, Jan Jaap R. and Fleming, Roland W.},
  year = {2017},
  month = mar,
  journal = {Journal of Vision},
  volume = {17},
  number = {3},
  pages = {18},
  issn = {1534-7362},
  doi = {10.1167/17.3.18},
  abstract = {Visually inferring the stiffness of objects is important for many tasks but is challenging because, unlike optical properties (e.g., gloss), mechanical properties do not directly affect image values. Stiffness must be inferred either (a) by recognizing materials and recalling their properties (associative approach) or (b) from shape and motion cues when the material is deformed (estimation approach). Here, we investigated interactions between these two inference types. Participants viewed renderings of unfamiliar shapes with 28 materials (e.g., nickel, wax, cork). In Experiment 1, they viewed nondeformed, static versions of the objects and rated 11 material attributes (e.g., soft, fragile, heavy). The results confirm that the optical materials elicited a wide range of apparent properties. In Experiment 2, using a blue plastic material with intermediate apparent softness, the objects were subjected to physical simulations of 12 shape-transforming processes (e.g., twisting, crushing, stretching). Participants rated softness and extent of deformation. Both correlated with the physical magnitude of deformation. Experiment 3 combined variations in optical cues with shape cues. We find that optical cues completely dominate. Experiment 4 included the entire motion sequence of the deformation, yielding significant contributions of optical as well as motion cues. Our findings suggest participants integrate shape, motion, and optical cues to infer stiffness, with optical cues playing a major role for our range of stimuli.},
  file = {/home/dek/Zotero/storage/B97XUKDR/Schmidt et al. - 2017 - Inferring the stiffness of unfamiliar objects from.pdf;/home/dek/Zotero/storage/9JFL8ULE/article.html}
}

@article{schmidtSoftnessWeightShape2020,
  title = {Softness and Weight from Shape: {{Material}} Properties Inferred from Local Shape Features},
  shorttitle = {Softness and Weight from Shape},
  author = {Schmidt, Filipp and Fleming, Roland W. and Valsecchi, Matteo},
  year = {2020},
  month = jun,
  journal = {Journal of Vision},
  volume = {20},
  number = {6},
  pages = {2},
  issn = {1534-7362},
  doi = {10.1167/jov.20.6.2},
  abstract = {Object shape is an important cue to material identity and for the estimation of material properties. Shape features can affect material perception at different levels: at a microscale (surface roughness), mesoscale (textures and local object shape), or megascale (global object shape) level. Examples for local shape features include ripples in drapery, clots in viscous liquids, or spiraling creases in twisted objects. Here, we set out to test the role of such shape features on judgments of material properties softness and weight. For this, we created a large number of novel stimuli with varying surface shape features. We show that those features have distinct effects on softness and weight ratings depending on their type, as well as amplitude and frequency, for example, increasing numbers and pointedness of spikes makes objects appear harder and heavier. By also asking participants to name familiar objects, materials, and transformations they associate with our stimuli, we can show that softness and weight judgments do not merely follow from semantic associations between particular stimuli and real-world object shapes. Rather, softness and weight are estimated from surface shape, presumably based on learned heuristics about the relationship between a particular expression of surface features and material properties. In line with this, we show that correlations between perceived softness or weight and surface curvature vary depending on the type of surface feature. We conclude that local shape features have to be considered when testing the effects of shape on the perception of material properties such as softness and weight.},
  file = {/home/dek/Zotero/storage/UT6G9GWF/Schmidt et al. - 2020 - Softness and weight from shape Material propertie.pdf}
}

@article{shepardAnalysisProximitiesMultidimensional1962,
  title = {The Analysis of Proximities: {{Multidimensional}} Scaling with an Unknown Distance Function. {{I}}.},
  shorttitle = {The Analysis of Proximities},
  author = {Shepard, Roger N.},
  year = {1962},
  month = jun,
  journal = {Psychometrika},
  volume = {27},
  number = {2},
  pages = {125--140},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02289630},
  langid = {english},
  file = {/home/dek/Zotero/storage/9QTE5NPM/Shepard - 1962 - The analysis of proximities Multidimensional scal.pdf}
}

@article{shepardApproximationUniformGradients1965,
  ids = {shepardApproximationUniformGradients1965b},
  title = {Approximation to Uniform Gradients of Generalization by Monotone Transformations of Scale},
  author = {Shepard, Roger N},
  year = {1965},
  journal = {Stimulus generalization},
  pages = {94--110}
}

@article{shepardAttentionMetricStructure1964,
  title = {Attention and the Metric Structure of the Stimulus Space},
  author = {Shepard, Roger N.},
  year = {1964},
  month = jan,
  journal = {Journal of Mathematical Psychology},
  volume = {1},
  number = {1},
  pages = {54--87},
  issn = {0022-2496},
  doi = {10.1016/0022-2496(64)90017-3},
  abstract = {Three experiments were performed in an investigation of how differences in size and inclination combine to determine the over-all similarity between otherwise identical visual stimuli. Similarity was defined both in terms of direct subjective judgments of over-all resemblance and in terms of the frequencies with which the stimuli were actually confused during identification learning. The results were incompatible with the static, Euclidean metric assumed by multidimensional scaling models. Apparently, when the stimuli vary along perceptually distinct dimensions, the psychological metric changes as subjects shift their attention more to one dimension or the other. The interstimulus similarities for any one state of attention, however, appear to conform with a Minkowski metric somewhere between the Euclidean and ``city-block'' varieties.},
  langid = {english},
  file = {/home/dek/Zotero/storage/5GHCVDQL/Shepard - 1964 - Attention and the metric structure of the stimulus.pdf;/home/dek/Zotero/storage/3YIRWM7Y/0022249664900173.html}
}

@article{singhPerceptualTheoryTransparency2002a,
  title = {Toward a Perceptual Theory of Transparency},
  author = {Singh, Manish and Anderson, Barton L.},
  year = {2002},
  journal = {Psychological Review},
  volume = {109},
  number = {3},
  pages = {492--519},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471},
  doi = {10.1037/0033-295X.109.3.492},
  abstract = {Theories of perceptual transparency have typically been developed within the context of a physical model that generates the percept of transparency (F. Metelli's episcotister model, 1974b). Here 2 fundamental questions are investigated: (a) When does the visual system initiate the percept of one surface seen through another? (b) How does it assign surface properties to a transparent layer? Results reveal systematic deviations from the predictions of Metelli's model, both for initiating image decomposition into multiple surfaces and for assigning surface attributes. Specifically, results demonstrate that the visual system uses Michelson contrast as a critical image variable to initiate percepts of transparency and to assign transmittance to transparent surfaces. Findings are discussed in relation to previous theories of transparency, lightness, brightness, and contrast-contrast. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Mathematical Modeling,Models,Stimulus Parameters,Theories,Visual Contrast,Visual Perception},
  file = {/home/dek/Zotero/storage/9AEUHB3T/2002-13781-003.html}
}

@article{storrsUnsupervisedLearningPredicts2021,
  title = {Unsupervised Learning Predicts Human Perception and Misperception of Gloss},
  author = {Storrs, Katherine R. and Anderson, Barton L. and Fleming, Roland W.},
  year = {2021},
  month = oct,
  journal = {Nature Human Behaviour},
  volume = {5},
  number = {10},
  pages = {1402--1417},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-021-01097-6},
  abstract = {Reflectance, lighting and geometry combine in complex ways to create images. How do we disentangle these to perceive individual properties, such as surface glossiness? We suggest that brains disentangle properties by learning to model statistical structure in proximal images. To test this hypothesis, we trained unsupervised generative neural networks on renderings of glossy surfaces and compared their representations with human gloss judgements. The networks spontaneously cluster images according to distal properties such as reflectance and illumination, despite receiving no explicit information about these properties. Intriguingly, the resulting representations also predict the specific patterns of `successes' and `errors' in human perception. Linearly decoding specular reflectance from the model's internal code predicts human gloss perception better than ground truth, supervised networks or control models, and it predicts, on an image-by-image basis, illusions of gloss perception caused by interactions between material, shape and lighting. Unsupervised learning may underlie many perceptual dimensions in vision and beyond.},
  copyright = {2021 The Author(s)},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Human behaviour;Object vision;Sensory processing Subject\_term\_id: human-behaviour;object-vision;sensory-processing},
  file = {/home/dek/Zotero/storage/YM9WJSJ2/Storrs et al_2021_Unsupervised learning predicts human perception and misperception of gloss.pdf;/home/dek/Zotero/storage/IK2ZCM47/s41562-021-01097-6.html}
}

@article{tabaghiGeometrySimilarityComparisons2021,
  ids = {tabaghiGeometryComparisons2020},
  title = {Geometry of {{Similarity Comparisons}}},
  author = {Tabaghi, Puoya and Peng, Jianhao and Milenkovic, Olgica and Dokmani{\'c}, Ivan},
  year = {2021},
  month = jul,
  journal = {arXiv:2006.09858 [cs, eess, stat]},
  eprint = {2006.09858},
  eprinttype = {arxiv},
  primaryclass = {cs, eess, stat},
  abstract = {Many data analysis problems can be cast as distance geometry problems in space forms \textendash{} Euclidean, spherical, or hyperbolic spaces. Often, absolute distance measurements are often unreliable or simply unavailable and only proxies to absolute distances in the form of similarities are available. Hence we ask the following: Given only comparisons of similarities amongst a set of entities, what can be said about the geometry of the underlying space form? To study this question, we introduce the notions of the ordinal capacity of a target space form and ordinal spread of the similarity measurements. The latter is an indicator of complex patterns in the measurements, while the former quantifies the capacity of a space form to accommodate a set of measurements with a specific ordinal spread profile. We prove that the ordinal capacity of a space form is related to its dimension and the sign of its curvature. This leads to a lower bound on the Euclidean and spherical embedding dimension of what we term similarity graphs. More importantly, we show that the statistical behavior of the ordinal spread random variables defined on a similarity graph can be used to identify its underlying space form. We support our theoretical claims with experiments on weighted trees, single-cell RNA expression data and spherical cartographic measurements.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Signal Processing,Statistics - Machine Learning},
  file = {/home/dek/Zotero/storage/M6KXIF9U/Tabaghi et al. - 2021 - Geometry of Similarity Comparisons.pdf;/home/dek/Zotero/storage/U2WKSIGU/2006.html}
}

@article{talagrandNewLookIndependence1996,
  title = {A New Look at Independence},
  author = {Talagrand, Michel},
  year = {1996},
  journal = {The Annals of probability},
  pages = {1--34},
  publisher = {{JSTOR}},
  file = {/home/dek/Zotero/storage/ED5HVW32/Talagrand - A NEW LOOK AT INDEPENDENCE.pdf}
}

@inproceedings{tamuzAdaptivelyLearningCrowd2011,
  title = {Adaptively Learning the Crowd Kernel},
  booktitle = {Proceedings of the 28th {{International Conference}} on {{International Conference}} on {{Machine Learning}}},
  author = {Tamuz, Omer and Liu, Ce and Belongie, Serge and Shamir, Ohad and Kalai, Adam Tauman},
  year = {2011},
  month = jun,
  series = {{{ICML}}'11},
  pages = {673--680},
  publisher = {{Omnipress}},
  address = {{Madison, WI, USA}},
  abstract = {We introduce an algorithm that, given n objects, learns a similarity matrix over all n2 pairs, from crowdsourced data alone. The algorithm samples responses to adaptively chosen triplet-based relative-similarity queries. Each query has the form "is object a more similar to b or to c?" and is chosen to be maximally informative given the preceding responses. The output is an embedding of the objects into Euclidean space (like MDS); we refer to this as the "crowd kernel." SVMs reveal that the crowd kernel captures prominent and subtle features across a number of domains, such as "is striped" among neckties and "vowel vs. consonant" among letters.},
  isbn = {978-1-4503-0619-5},
  file = {/home/dek/Zotero/storage/BLILPZ8C/Tamuz et al. - Adaptively Learning the Crowd Kernel.pdf}
}

@inproceedings{teradaLocalOrdinalEmbedding2014,
  title = {Local Ordinal Embedding},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Terada, Yoshikazu and Luxburg, Ulrike},
  year = {2014},
  pages = {847--855},
  file = {/home/dek/Zotero/storage/DB25R4KV/Terada - Supplementary Material for Local Ordinal Embedding.pdf;/home/dek/Zotero/storage/S9B39DX4/Terada - Local Ordinal Embedding.pdf}
}

@article{torgersonMultidimensionalScalingTheory1952a,
  title = {Multidimensional Scaling: {{I}}. {{Theory}} and Method},
  shorttitle = {Multidimensional Scaling},
  author = {Torgerson, Warren S.},
  year = {1952},
  month = dec,
  journal = {Psychometrika},
  volume = {17},
  number = {4},
  pages = {401--419},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02288916},
  langid = {english},
  file = {/home/dek/Zotero/storage/EDCJVXAU/Torgerson - 1952 - Multidimensional scaling I. Theory and method.pdf}
}

@article{toscaniThreePerceptualDimensions2020,
  title = {Three {{Perceptual Dimensions}} for {{Specular}} and {{Diffuse Reflection}}},
  author = {Toscani, Matteo and Guarnera, Dar'ya and Guarnera, Giuseppe Claudio and Hardeberg, Jon Yngve and Gegenfurtner, Karl R.},
  year = {2020},
  month = may,
  journal = {ACM Transactions on Applied Perception},
  volume = {17},
  number = {2},
  pages = {6:1--6:26},
  issn = {1544-3558},
  doi = {10.1145/3380741},
  abstract = {Previous research investigated the perceptual dimensionality of achromatic reflection of opaque surfaces, by using either simple analytic models of reflection or measured reflection properties of a limited sample of materials. Here, we aim to extend this work to a broader range of simulated materials. In a first experiment, we used sparse multidimensional scaling techniques to represent a set of rendered stimuli in a perceptual space that is consistent with participants' similarity judgments. Participants were presented with one reference object and four comparisons, rendered with different material properties. They were asked to rank the comparisons according to their similarity to the reference, resulting in an efficient collection of a large number of similarity judgments. To interpret the space individuated by multidimensional scaling, we ran a second experiment in which observers were asked to rate our experimental stimuli according to a list of 30 adjectives referring to their surface reflectance properties. Our results suggest that perception of achromatic reflection is based on at least three dimensions, which we labelled ``Lightness,'' ``Gloss,'' and ``Metallicity,'' in accordance with the rating results. These dimensions are characterized by a relatively simple relationship with the parameters of the physically based rendering model used to generate our stimuli, indicating that they correspond to different physical properties of the rendered materials. Specifically, ``Lightness'' relates to diffuse reflections, ``Gloss'' to the presence of high contrast sharp specular highlights, and ``Metallicity'' to spread out specular reflections.},
  keywords = {BRDF,dimensionality,Perception},
  file = {/home/dek/Zotero/storage/JPLAT7QY/Toscani et al_2020_Three Perceptual Dimensions for Specular and Diffuse Reflection.pdf}
}

@article{trunkStasticalEstimationIntrinsic1976,
  title = {Stastical {{Estimation}} of the {{Intrinsic Dimensionality}} of a {{Noisy Signal Collection}}},
  author = {Trunk, G. V.},
  year = {1976},
  month = feb,
  journal = {IEEE Transactions on Computers},
  volume = {C-25},
  number = {2},
  pages = {165--171},
  issn = {1557-9956},
  doi = {10.1109/TC.1976.5009231},
  abstract = {Let W be an N-dimensional vector space and let the signal locus V be a K-dimensional topological hypersurface in W. The intrinsic dimensionality problem can be stated as follows. Given M randomly selected points (signals) vi, vi {$\epsilon$} V, estimate K, which is the dimensionality of V and is called the intrinsic dimensionality of the points vi. A statistical method, which is developed from geometric considerations, is used to estimate the dimensionality. This ad hoc statistical method avoids the approximations and assumptions required by the maximum likelihood solution. The problem of estimating dimensionality in the presence of additive white noise is also considered. A pseudo, signal-to-noise ratio, which has meaning with respect to estimating the dimensionality of a noisy signal collection, is defined. A filtering method, based on this ratio, is used to estimate the dimensionality of a noisy signal collection. The accuracy of the method is demonstrated by estimating the dimensionality of a collection of pulsed signals which have four free parameters.},
  keywords = {Data mining,Estimation,Intrinsic dimensionality,Noise,Noise measurement,parameter identification,pattern recognition,Petroleum,signal collection,Statistical analysis,statistical estimation,topological dimensionality,Vectors},
  file = {/home/dek/Zotero/storage/B8USXY3J/5009231.html}
}

@book{umbachDimensionalityPerceptualSpace2014,
  title = {Dimensionality of the Perceptual Space of Achromatic Surface Colors},
  author = {Umbach, Nora},
  year = {2014},
  edition = {First},
  pages = {149},
  publisher = {{Hut}},
  address = {{M\"unchen}},
  isbn = {978-3-8439-1517-5},
  file = {/home/dek/Zotero/storage/4DFH8TCE/dissertation_umbach.pdf;/home/dek/Zotero/storage/T54ZPQFK/PPNSET.html}
}

@article{vanassenVisualFeaturesPerception2018,
  title = {Visual {{Features}} in the {{Perception}} of {{Liquids}}},
  author = {{van Assen}, Jan Jaap R. and Barla, Pascal and Fleming, Roland W.},
  year = {2018},
  month = feb,
  journal = {Current biology: CB},
  volume = {28},
  number = {3},
  pages = {452-458.e4},
  issn = {1879-0445},
  doi = {10.1016/j.cub.2017.12.037},
  abstract = {Perceptual constancy-identifying surfaces and objects across large image changes-remains an important challenge for visual neuroscience [1-8]. Liquids are particularly challenging because they respond to external forces in complex, highly variable ways, presenting an enormous range of images to the visual system. To achieve constancy, the brain must perform a causal inference [9-11] that disentangles the liquid's viscosity from external factors-like gravity and object interactions-that also affect the liquid's behavior. Here, we tested whether the visual system estimates viscosity using "midlevel" features [12-14] that respond more to viscosity than other factors. Observers reported the perceived viscosity of simulated liquids ranging from water to molten glass exhibiting diverse behaviors (e.g., pouring, stirring). A separate group of observers rated the same animations for 20 midlevel 3D shape and motion features. Applying factor analysis to the feature ratings reveals that a weighted combination of four underlying factors (distribution, irregularity, rectilinearity, and dynamics) predicted perceived viscosity very well across this wide range of contexts (R2~= 0.93). Interestingly, observers unknowingly ordered their midlevel judgments according to the one common factor across contexts: variation in viscosity. Principal component analysis reveals that across the features, the first component lines up almost perfectly with the viscosity (R2~= 0.96). Our findings demonstrate that the visual system achieves constancy by representing stimuli in a multidimensional feature space-based on complementary, midlevel features-which successfully cluster very different stimuli together and tease similar stimuli apart, so that viscosity can be read out easily.},
  langid = {english},
  pmcid = {PMC5807092},
  pmid = {29395924},
  keywords = {Adult,Female,Form Perception,Humans,Judgment,liquid,Male,material appearance,midlevel features,perception,perceptual constancy,Photic Stimulation,recognition,viscosity,Viscosity,visual features,Visual Perception,Young Adult},
  file = {/home/dek/Zotero/storage/9S5KR3WW/van Assen et al. - 2018 - Visual Features in the Perception of Liquids.pdf}
}

@inproceedings{vandermaatenStochasticTripletEmbedding2012,
  title = {Stochastic Triplet Embedding},
  booktitle = {2012 {{IEEE International Workshop}} on {{Machine Learning}} for {{Signal Processing}}},
  author = {{van der Maaten}, Laurens and Weinberger, Kilian},
  year = {2012},
  month = sep,
  pages = {1--6},
  publisher = {{IEEE}},
  address = {{Santander, Spain}},
  doi = {10.1109/MLSP.2012.6349720},
  abstract = {This paper considers the problem of learning an embedding of data based on similarity triplets of the form ``A is more similar to B than to C''. This learning setting is of relevance to scenarios in which we wish to model human judgements on the similarity of objects. We argue that in order to obtain a truthful embedding of the underlying data, it is insufficient for the embedding to satisfy the constraints encoded by the similarity triplets. In particular, we introduce a new technique called t-Distributed Stochastic Triplet Embedding (t-STE) that collapses similar points and repels dissimilar points in the embedding \textemdash{} even when all triplet constraints are satisfied. Our experimental evaluation on three data sets shows that as a result, t-STE is much better than existing techniques at revealing the underlying data structure.},
  isbn = {978-1-4673-1026-0 978-1-4673-1024-6 978-1-4673-1025-3},
  langid = {english},
  file = {/home/dek/Zotero/storage/PCDFFYBT/van der Maaten und Weinberger - 2012 - Stochastic triplet embedding.pdf}
}

@article{vankadaraInsightsOrdinalEmbedding2020,
  title = {Insights into {{Ordinal Embedding Algorithms}}: {{A Systematic Evaluation}}},
  shorttitle = {Insights into {{Ordinal Embedding Algorithms}}},
  author = {Vankadara, Leena Chennuru and Haghiri, Siavash and Lohaus, Michael and Wahab, Faiz Ul and {von Luxburg}, Ulrike},
  year = {2020},
  month = dec,
  journal = {arXiv:1912.01666 [cs, stat]},
  eprint = {1912.01666},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {The objective of ordinal embedding is to find a Euclidean representation of a set of abstract items, using only answers to triplet comparisons of the form "Is item \$i\$ closer to the item \$j\$ or item \$k\$?". In recent years, numerous algorithms have been proposed to solve this problem. However, there does not exist a fair and thorough assessment of these embedding methods and therefore several key questions remain unanswered: Which algorithms scale better with increasing sample size or dimension? Which ones perform better when the embedding dimension is small or few triplet comparisons are available? In our paper, we address these questions and provide the first comprehensive and systematic empirical evaluation of existing algorithms as well as a new neural network approach. In the large triplet regime, we find that simple, relatively unknown, non-convex methods consistently outperform all other algorithms, including elaborate approaches based on neural networks or landmark approaches. This finding can be explained by our insight that many of the non-convex optimization approaches do not suffer from local optima. In the low triplet regime, our neural network approach is either competitive or significantly outperforms all the other methods. Our comprehensive assessment is enabled by our unified library of popular embedding algorithms that leverages GPU resources and allows for fast and accurate embeddings of millions of data points.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/dek/Zotero/storage/DLUMZJW6/Vankadara et al. - 2020 - Insights into Ordinal Embedding Algorithms A Syst.pdf;/home/dek/Zotero/storage/GHFZB4QR/Vankadara et al_2020_Insights into Ordinal Embedding Algorithms.pdf;/home/dek/Zotero/storage/7D8GRBPJ/1912.html}
}

@incollection{wichmannMethodsPsychophysics2018,
  title = {Methods in {{Psychophysics}}},
  booktitle = {Stevens' {{Handbook}} of {{Experimental Psychology}} and {{Cognitive Neuroscience}}},
  author = {Wichmann, Felix A. and J{\"a}kel, Frank},
  editor = {Wixted, John T.},
  year = {2018},
  month = mar,
  pages = {1--42},
  publisher = {{John Wiley \& Sons, Inc.}},
  address = {{Hoboken, NJ, USA}},
  doi = {10.1002/9781119170174.epcn507},
  isbn = {978-1-119-17016-7 978-1-119-17017-4},
  langid = {english},
  file = {/home/dek/Zotero/storage/7GA966RI/Wichmann and Jäkel - 2018 - Methods in Psychophysics.pdf}
}

@article{willsPerceptualSpaceGloss2009,
  title = {Toward a Perceptual Space for Gloss},
  author = {Wills, Josh and Agarwal, Sameer and Kriegman, David and Belongie, Serge},
  year = {2009},
  month = aug,
  journal = {ACM Transactions on Graphics},
  volume = {28},
  number = {4},
  pages = {1--15},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/1559755.1559760},
  langid = {english},
  file = {/home/dek/Zotero/storage/7W62FWYP/Wills et al. - 2009 - Toward a perceptual space for gloss.pdf}
}


